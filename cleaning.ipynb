{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading data from given dataset</h3> \n",
    "\n",
    "The dataset file has to be stored with the name 'dataset.csv'.   \n",
    "We first load the dataset file as a df using pandas.   \n",
    "We extract the product categories tree and description as we wish to build our model using these two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   product_category_tree  \\\n",
      "0      [\"Clothing >> Women's Clothing >> Lingerie, Sl...   \n",
      "1      [\"Furniture >> Living Room Furniture >> Sofa B...   \n",
      "2      [\"Footwear >> Women's Footwear >> Ballerinas >...   \n",
      "3      [\"Clothing >> Women's Clothing >> Lingerie, Sl...   \n",
      "4      [\"Pet Supplies >> Grooming >> Skin & Coat Care...   \n",
      "...                                                  ...   \n",
      "19995  [\"Baby Care >> Baby & Kids Gifts >> Stickers >...   \n",
      "19996  [\"Baby Care >> Baby & Kids Gifts >> Stickers >...   \n",
      "19997  [\"Baby Care >> Baby & Kids Gifts >> Stickers >...   \n",
      "19998  [\"Baby Care >> Baby & Kids Gifts >> Stickers >...   \n",
      "19999  [\"Baby Care >> Baby & Kids Gifts >> Stickers >...   \n",
      "\n",
      "                                             description  \n",
      "0      Key Features of Alisha Solid Women's Cycling S...  \n",
      "1      FabHomeDecor Fabric Double Sofa Bed (Finish Co...  \n",
      "2      Key Features of AW Bellies Sandals Wedges Heel...  \n",
      "3      Key Features of Alisha Solid Women's Cycling S...  \n",
      "4      Specifications of Sicons All Purpose Arnica Do...  \n",
      "...                                                  ...  \n",
      "19995  Buy WallDesign Small Vinyl Sticker for Rs.730 ...  \n",
      "19996  Buy Wallmantra Large Vinyl Stickers Sticker fo...  \n",
      "19997  Buy Elite Collection Medium Acrylic Sticker fo...  \n",
      "19998  Buy Elite Collection Medium Acrylic Sticker fo...  \n",
      "19999  Buy Elite Collection Medium Acrylic Sticker fo...  \n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset.csv\",usecols = ['product_category_tree','description'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extracting categories from the product category tree </h3>\n",
    "\n",
    " In the dataset, we have been provided with the entire product category tree which leads us to the product, every category has been divided into few subcategories which lead to the final product. Since the length of each product is variable and every product has atleast one main category(root of tree), we will be using the wider categories as the main category for classificaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree                                        description\n",
      "0                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "1                 furniture  FabHomeDecor Fabric Double Sofa Bed (Finish Co...\n",
      "2                  footwear  Key Features of AW Bellies Sandals Wedges Heel...\n",
      "3                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "4              pet supplies  Specifications of Sicons All Purpose Arnica Do...\n",
      "...                     ...                                                ...\n",
      "19995             baby care  Buy WallDesign Small Vinyl Sticker for Rs.730 ...\n",
      "19996             baby care  Buy Wallmantra Large Vinyl Stickers Sticker fo...\n",
      "19997             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19998             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19999             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"dataset.csv\",usecols = ['product_category_tree','description'])\n",
    "cat_map =  dict()#cat map is a dictionary that stores all classes and their frequency\n",
    "for index in df2.index:\n",
    "    x = df2.loc[index,'product_category_tree']\n",
    "    x = x.strip(\"[]\\\"\")#removing unnecessary symbols from the tree\n",
    "    y = x.split(\">>\")#splitting the tree into an array of categories\n",
    "    z = y[0].strip().lower()#removing trailing spaces and lowercasing \n",
    "    if(z in cat_map.keys()):\n",
    "        cat_map[z] += 1\n",
    "    else:\n",
    "        cat_map[z] = 1\n",
    "    df2.loc[index,'product_category_tree'] = z\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6198\n"
     ]
    }
   ],
   "source": [
    "print(cat_map['clothing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dealing with categories that have extremely few data points</h3>\n",
    "\n",
    "We wish to make our model capable of predicting a large number of categories, however too many categories have only one or two datapoints only, so we will be clubbing them under an 'others' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in df2.index:\n",
    "    x = df2.loc[index,'product_category_tree']\n",
    "    if(cat_map[x]<=10):#categories with less than 10 points go to others category\n",
    "        df2.loc[index,'product_category_tree'] = 'others'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree                                        description\n",
      "0                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "1                 furniture  FabHomeDecor Fabric Double Sofa Bed (Finish Co...\n",
      "2                  footwear  Key Features of AW Bellies Sandals Wedges Heel...\n",
      "3                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "4              pet supplies  Specifications of Sicons All Purpose Arnica Do...\n",
      "...                     ...                                                ...\n",
      "19995             baby care  Buy WallDesign Small Vinyl Sticker for Rs.730 ...\n",
      "19996             baby care  Buy Wallmantra Large Vinyl Stickers Sticker fo...\n",
      "19997             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19998             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19999             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cleaning the description text</h3>\n",
    "\n",
    "We will be performing some standard procedures on the description text so that it can be ready to be used efficiently in the model such as removing special expressions, accented characters(if available), stopwords, lemmetization etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing accented characters</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "# function to remove accented characters\n",
    "def remove_accented_chars(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing punctuation,special characters and numbers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "# function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, '', text)\n",
    "def remove_numbers(text):\n",
    "    # define the pattern to keep\n",
    "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pattern, '', text)\n",
    "# imports\n",
    "import string\n",
    "# function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lemmetization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def get_lem(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we be eat and swimming ; we have be eat and swim ; he eat and swim ; he eat and swam\n"
     ]
    }
   ],
   "source": [
    "print(get_lem(\"we are eating and swimming ; we have been eating and swimming ; he eats and swims ; he ate and swam \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing Stopwords</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    filtered_sentence = (\" \").join(tokens_without_sw)\n",
    "    return(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nick likes play football , however fond tennis .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"Nick likes to play football, however he is not too fond of tennis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing unnecessary whitespaces and tabs </h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespace_tabs(text):\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()\n",
    "def to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree                                        description\n",
      "0                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "1                 furniture  FabHomeDecor Fabric Double Sofa Bed (Finish Co...\n",
      "2                  footwear  Key Features of AW Bellies Sandals Wedges Heel...\n",
      "3                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "4              pet supplies  Specifications of Sicons All Purpose Arnica Do...\n",
      "...                     ...                                                ...\n",
      "19995             baby care  Buy WallDesign Small Vinyl Sticker for Rs.730 ...\n",
      "19996             baby care  Buy Wallmantra Large Vinyl Stickers Sticker fo...\n",
      "19997             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19998             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19999             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Before performing all these functions on our data we will remove the examples which has no description at all </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "553\n",
      "nan\n",
      "17299\n"
     ]
    }
   ],
   "source": [
    "for index in df2.index:\n",
    "    x = df2.loc[index,'description']\n",
    "    if(isinstance(x,str)==False):\n",
    "        print(x)\n",
    "        print(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Since there are only 2 such examples we remove them directly </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree                                        description\n",
      "0                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "1                 furniture  FabHomeDecor Fabric Double Sofa Bed (Finish Co...\n",
      "2                  footwear  Key Features of AW Bellies Sandals Wedges Heel...\n",
      "3                  clothing  Key Features of Alisha Solid Women's Cycling S...\n",
      "4              pet supplies  Specifications of Sicons All Purpose Arnica Do...\n",
      "...                     ...                                                ...\n",
      "19995             baby care  Buy WallDesign Small Vinyl Sticker for Rs.730 ...\n",
      "19996             baby care  Buy Wallmantra Large Vinyl Stickers Sticker fo...\n",
      "19997             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19998             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "19999             baby care  Buy Elite Collection Medium Acrylic Sticker fo...\n",
      "\n",
      "[19998 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new = df2.drop([553,17299])\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Performing all cleaning operations on the description field</h4>\n",
    "\n",
    "We iterate through the dataset and clean the description field for all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in df_new.index:\n",
    "    x = df_new.loc[index,'description']\n",
    "    x = to_lowercase(x)\n",
    "    x = remove_extra_whitespace_tabs(x)\n",
    "    x = remove_accented_chars(x)\n",
    "    x = remove_special_characters(x)\n",
    "    x = remove_numbers(x)\n",
    "    x = remove_punctuation(x)\n",
    "    x = remove_stopwords(x)\n",
    "    df_new.loc[index,'description'] = x\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = df_new\n",
    "for index in df_parsed.index:\n",
    "    x = df_parsed.loc[index,'description']\n",
    "    x = get_lem(x)\n",
    "    df_parsed.loc[index,'description'] = x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving current progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree                                        description\n",
      "0                  clothing  key feature alisha solid women cycling short c...\n",
      "1                 furniture  fabhomedecor fabric double sofa bed finish col...\n",
      "2                  footwear  key feature aw belly sandal wedge heel casuals...\n",
      "3                  clothing  key feature alisha solid women cycling short c...\n",
      "4              pet supplies  specification sicon purpose arnica shampoo ml ...\n",
      "...                     ...                                                ...\n",
      "19995             baby care  buy walldesign small vinyl sticker rs online w...\n",
      "19996             baby care  buy wallmantra large vinyl sticker sticker rs ...\n",
      "19997             baby care  buy elite collection medium acrylic sticker rs...\n",
      "19998             baby care  buy elite collection medium acrylic sticker rs...\n",
      "19999             baby care  buy elite collection medium acrylic sticker rs...\n",
      "\n",
      "[19998 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed.to_csv('out_parsed.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Attaching labels to the each product category</h3>\n",
    "\n",
    "We will assign each product category a number as we do in most text classification tasks, it will make it easy to work with the data\n",
    "\n",
    "We wish to make a classifier that can predict maximum number of categories, however few categories still have less datapoints. We thus make 3 csv files. In first file all the categories with less than 10 datapoints are assigned an 'others category' which we have already done.For the second and third we set this cutoff as 100 and 500 respectively. We will be using the next two files only if classification doesn't work on the first file as one of our aims also is to make the classifier to predict a large number of categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clothing': 0, 'furniture': 1, 'footwear': 2, 'pet supplies': 3, 'pens & stationery': 4, 'sports & fitness': 5, 'beauty and personal care': 6, 'bags, wallets & belts': 7, 'home decor & festive needs': 8, 'automotive': 9, 'tools & hardware': 10, 'home furnishing': 11, 'baby care': 12, 'mobiles & accessories': 13, 'watches': 14, 'toys & school supplies': 15, 'jewellery': 16, 'sunglasses': 17, 'kitchen & dining': 18, 'home & kitchen': 19, 'computers': 20, 'cameras & accessories': 21, 'health & personal care appliances': 22, 'gaming': 23, 'home improvement': 24, 'home entertainment': 25, 'ebooks': 26, 'others': 27}\n",
      "{'clothing': 0, 'furniture': 1, 'footwear': 2, 'pens & stationery': 3, 'sports & fitness': 4, 'beauty and personal care': 5, 'bags, wallets & belts': 6, 'home decor & festive needs': 7, 'automotive': 8, 'tools & hardware': 9, 'home furnishing': 10, 'baby care': 11, 'mobiles & accessories': 12, 'watches': 13, 'toys & school supplies': 14, 'jewellery': 15, 'kitchen & dining': 16, 'computers': 17, 'others': 18}\n",
      "{'clothing': 0, 'footwear': 1, 'beauty and personal care': 2, 'home decor & festive needs': 3, 'automotive': 4, 'home furnishing': 5, 'mobiles & accessories': 6, 'watches': 7, 'jewellery': 8, 'kitchen & dining': 9, 'computers': 10, 'others': 11}\n"
     ]
    }
   ],
   "source": [
    "label_list1 =  dict()\n",
    "counter1 = 0\n",
    "label_list2 =  dict()\n",
    "counter2 = 0\n",
    "label_list3 =  dict()\n",
    "counter3 = 0\n",
    "\n",
    "for k,v in cat_map.items():\n",
    "    if(v>10):\n",
    "        label_list1[k]=counter1\n",
    "        counter1+= 1\n",
    "    if(v>100):\n",
    "        label_list2[k]=counter2\n",
    "        counter2+= 1\n",
    "    if(v>500):\n",
    "        label_list3[k]=counter3\n",
    "        counter3+= 1\n",
    "label_list1['others'] = counter1\n",
    "label_list2['others'] = counter2\n",
    "label_list3['others'] = counter3\n",
    "\n",
    "print(label_list1)\n",
    "print(label_list2)\n",
    "print(label_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = pd.read_csv('out_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree                                        description\n",
      "0                  clothing  key feature alisha solid women cycling short c...\n",
      "1                 furniture  fabhomedecor fabric double sofa bed finish col...\n",
      "2                  footwear  key feature aw belly sandal wedge heel casuals...\n",
      "3                  clothing  key feature alisha solid women cycling short c...\n",
      "4              pet supplies  specification sicon purpose arnica shampoo ml ...\n",
      "...                     ...                                                ...\n",
      "19993             baby care  buy walldesign small vinyl sticker rs online w...\n",
      "19994             baby care  buy wallmantra large vinyl sticker sticker rs ...\n",
      "19995             baby care  buy elite collection medium acrylic sticker rs...\n",
      "19996             baby care  buy elite collection medium acrylic sticker rs...\n",
      "19997             baby care  buy elite collection medium acrylic sticker rs...\n",
      "\n",
      "[19998 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Assigning labels from the label list to their corresponding categories and saving the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_category_tree  \\\n",
      "0                  clothing   \n",
      "1                 furniture   \n",
      "2                  footwear   \n",
      "3                  clothing   \n",
      "4              pet supplies   \n",
      "...                     ...   \n",
      "19993             baby care   \n",
      "19994             baby care   \n",
      "19995             baby care   \n",
      "19996             baby care   \n",
      "19997             baby care   \n",
      "\n",
      "                                             description  label  \n",
      "0      key feature alisha solid women cycling short c...      0  \n",
      "1      fabhomedecor fabric double sofa bed finish col...      1  \n",
      "2      key feature aw belly sandal wedge heel casuals...      2  \n",
      "3      key feature alisha solid women cycling short c...      0  \n",
      "4      specification sicon purpose arnica shampoo ml ...      3  \n",
      "...                                                  ...    ...  \n",
      "19993  buy walldesign small vinyl sticker rs online w...     12  \n",
      "19994  buy wallmantra large vinyl sticker sticker rs ...     12  \n",
      "19995  buy elite collection medium acrylic sticker rs...     12  \n",
      "19996  buy elite collection medium acrylic sticker rs...     12  \n",
      "19997  buy elite collection medium acrylic sticker rs...     12  \n",
      "\n",
      "[19998 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final1=df_parsed\n",
    "df_final1['label'] = df_final1['product_category_tree']\n",
    "df_final1 = df_final1.replace({'label':label_list1})\n",
    "print(df_final1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1.to_csv('outfinal1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2=df_parsed\n",
    "for index in df_final2.index:\n",
    "    x = df_final2.loc[index,'product_category_tree']\n",
    "    if(x=='others'):\n",
    "        continue\n",
    "    if(cat_map[x]<=100):\n",
    "      df_final2.loc[index,'product_category_tree'] = 'others'  \n",
    "df_final2['label'] = df_final2['product_category_tree']\n",
    "df_final2 = df_final2.replace({'label':label_list2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.to_csv('outfinal2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3=df_parsed\n",
    "for index in df_final3.index:\n",
    "    x = df_final3.loc[index,'product_category_tree']\n",
    "    if(x=='others'):\n",
    "        continue\n",
    "    if(cat_map[x]<=500):\n",
    "      df_final3.loc[index,'product_category_tree'] = 'others'\n",
    "df_final3['label'] = df_final3['product_category_tree']\n",
    "df_final3 = df_final3.replace({'label':label_list3})\n",
    "df_final3.to_csv('outfinal3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
